{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMBA Basal Ganglia Dataset: Comprehensive EDA & ML\n",
    "\n",
    "## Human and Mammalian Brain Atlas (HMBA) Basal Ganglia Dataset\n",
    "\n",
    "This notebook provides comprehensive exploratory data analysis and machine learning workflows for the HMBA Basal Ganglia single-nucleus RNA sequencing dataset.\n",
    "\n",
    "**Dataset Highlights:**\n",
    "- ~1.9 million nuclei across multiple primate species\n",
    "- 16,630 genes (one-to-one orthologs)\n",
    "- Hierarchical cell type taxonomy\n",
    "- Both raw and log2-transformed expression matrices\n",
    "\n",
    "**This notebook demonstrates:**\n",
    "1. Loading data via MLCommons Croissant metadata\n",
    "2. Comprehensive EDA with visualizations\n",
    "3. ML model training with PyTorch and TensorFlow\n",
    "4. Model behavior analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install mlcroissant pandas numpy matplotlib seaborn scikit-learn torch tensorflow -q\n",
    "\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import mlcroissant as mlc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('husl')\n\nprint(f\"pandas version: {pd.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load Dataset via FAIRÂ² Metadata\n\nThe FAIRÂ² JSON-LD file (based on the MLCommons Croissant standard) provides machine-readable metadata and enables loading data directly from the dataset's DOI-based URL."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the FAIRÂ² dataset from the DOI-based URL\nfair2_url = 'https://sen.science/doi/10.71728/senscience.xe0q-5vu6/fair2.json'\ndataset = mlc.Dataset(fair2_url)\nmetadata = dataset.metadata.to_json()\n\nprint(f\"Dataset: {metadata['name']}\")\nprint(f\"Version: {metadata.get('version', 'N/A')}\")\nprint(f\"License: {metadata.get('license', 'N/A')}\")\nprint(f\"\\nDescription: {metadata.get('description', 'N/A')[:200]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available files in the dataset\n",
    "distributions = metadata.get('distribution', [])\n",
    "\n",
    "print(f\"Dataset contains {len(distributions)} files:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Group by type\n",
    "h5ad_files = [d for d in distributions if 'hdf5' in d.get('encodingFormat', '')]\n",
    "parquet_files = [d for d in distributions if 'parquet' in d.get('encodingFormat', '')]\n",
    "csv_files = [d for d in distributions if 'csv' in d.get('encodingFormat', '')]\n",
    "\n",
    "print(f\"\\nðŸ“¦ H5AD Files ({len(h5ad_files)}):\")\n",
    "for f in h5ad_files:\n",
    "    print(f\"   â€¢ {f['name']}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Parquet Files ({len(parquet_files)}):\")\n",
    "for f in parquet_files:\n",
    "    print(f\"   â€¢ {f['name']}\")\n",
    "\n",
    "print(f\"\\nðŸ“„ CSV Files ({len(csv_files)}):\")\n",
    "for f in csv_files:\n",
    "    print(f\"   â€¢ {f['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Load Data via Croissant RecordSets\n\nWe'll load the dataset tables through the FAIRÂ² metadata using `dataset.records()`. The RecordSets read from Parquet files hosted at the dataset's DOI URL for significantly faster loading and smaller file sizes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Helper function to load records from Croissant dataset\ndef load_croissant_records(dataset, record_set_name, max_records=100000):\n    \"\"\"Load records from a Croissant dataset RecordSet into a DataFrame.\n    \n    Note: mlcroissant returns column names prefixed with the RecordSet ID\n    (e.g., 'donor_records/donor_label'). This function strips the prefix\n    to return clean column names matching the original CSV headers.\n    \n    When reading from Parquet files, mlcroissant may return string values\n    as bytes objects (e.g., b'Homo sapiens'). This function decodes them\n    back to Python str for seamless downstream use.\n    \"\"\"\n    try:\n        records = list(dataset.records(record_set=record_set_name))\n        if max_records and len(records) > max_records:\n            records = records[:max_records]\n        df = pd.DataFrame(records)\n        # Strip RecordSet prefix from column names (e.g., 'donor_records/donor_label' -> 'donor_label')\n        df.columns = [col.split('/')[-1] if '/' in col else col for col in df.columns]\n        # Decode bytes columns to str (mlcroissant + Parquet returns bytes for string fields)\n        for col in df.columns:\n            if df[col].dtype == object and len(df) > 0 and isinstance(df[col].iloc[0], bytes):\n                df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n        print(f\"âœ“ Loaded '{record_set_name}': {len(df):,} rows, {len(df.columns)} columns\")\n        return df\n    except Exception as e:\n        print(f\"âœ— Could not load '{record_set_name}': {e}\")\n        return None\n\n# List available RecordSets in Croissant metadata\nprint(\"=\"*70)\nprint(\"AVAILABLE RECORDSETS IN CROISSANT METADATA\")\nprint(\"=\"*70)\nrecord_sets = metadata.get('recordSet', [])\nfor rs in record_sets:\n    print(f\"  â€¢ {rs['@id']}: {rs['name']}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"LOADING DATA FROM CROISSANT RECORDSETS\")\nprint(\"=\"*70 + \"\\n\")\n\n# Load metadata tables via Croissant RecordSets (backed by Parquet files)\n# Core tables\ndf_donor = load_croissant_records(dataset, 'donor_records')\ndf_cluster = load_croissant_records(dataset, 'cluster_records')\ndf_taxonomy = load_croissant_records(dataset, 'cluster_annotation_term_records')\ndf_taxonomy_levels = load_croissant_records(dataset, 'cluster_annotation_term_set_records')\ndf_library = load_croissant_records(dataset, 'library_records')\ndf_gene = load_croissant_records(dataset, 'gene_csv_records')\n\n# Cell-level data (limited for performance)\ndf_cell_metadata = load_croissant_records(dataset, 'cell_metadata_csv_records', max_records=100000)\ndf_cell_cluster = load_croissant_records(dataset, 'cell_to_cluster_membership_records', max_records=100000)\ndf_embeddings = load_croissant_records(dataset, 'cell_2d_embedding_records', max_records=100000)\n\n# Annotation mappings\ndf_cluster_to_annotation = load_croissant_records(dataset, 'cluster_to_cluster_annotation_records')\ndf_abbreviations = load_croissant_records(dataset, 'cluster_annotation_to_abbreviation_records')\ndf_abbreviation_terms = load_croissant_records(dataset, 'abbreviation_term_records')\n\n# Reference tables\ndf_value_sets = load_croissant_records(dataset, 'value_sets_records')\ndf_example_expression = load_croissant_records(dataset, 'example_gene_expression_records')\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… ALL DATA LOADED VIA CROISSANT RECORDSETS (Parquet-backed)\")\nprint(\"=\"*70)\n\n# Summary of loaded data\nloaded_dfs = {\n    'donor': df_donor,\n    'cluster': df_cluster,\n    'taxonomy (terms)': df_taxonomy,\n    'taxonomy (levels)': df_taxonomy_levels,\n    'library': df_library,\n    'gene': df_gene,\n    'cell_metadata': df_cell_metadata,\n    'cell_cluster': df_cell_cluster,\n    'embeddings': df_embeddings,\n    'cluster_to_annotation': df_cluster_to_annotation,\n    'abbreviations_map': df_abbreviations,\n    'abbreviation_terms': df_abbreviation_terms,\n    'value_sets': df_value_sets,\n    'example_expression': df_example_expression\n}\n\nprint(\"\\nLoaded DataFrames Summary:\")\nfor name, df in loaded_dfs.items():\n    if df is not None:\n        print(f\"  {name}: {len(df):,} rows Ã— {len(df.columns)} cols\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "### 4.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset summary statistics\nprint(\"=\"*60)\nprint(\"HMBA BASAL GANGLIA DATASET OVERVIEW\")\nprint(\"=\"*60)\n\nif df_donor is not None:\n    print(f\"\\nðŸ§¬ Donors: {len(df_donor)}\")\n    if 'species_scientific_name' in df_donor.columns:\n        species_counts = df_donor['species_scientific_name'].value_counts()\n        for species, count in species_counts.items():\n            print(f\"   â€¢ {species}: {count} donors\")\n\nif df_cluster is not None:\n    print(f\"\\nðŸ”¬ Clusters: {len(df_cluster)}\")\n    if 'number_of_cells' in df_cluster.columns:\n        total_cells = df_cluster['number_of_cells'].sum()\n        print(f\"   â€¢ Total cells: {total_cells:,}\")\n\nif df_gene is not None:\n    print(f\"\\nðŸ§ª Genes: {len(df_gene):,}\")\n\nif df_library is not None:\n    print(f\"\\nðŸ“š Libraries: {len(df_library)}\")\n\nif df_taxonomy is not None:\n    print(f\"\\nðŸ“Š Taxonomy Terms: {len(df_taxonomy)}\")\n    if 'cluster_annotation_term_set_name' in df_taxonomy.columns:\n        term_sets = df_taxonomy['cluster_annotation_term_set_name'].unique()\n        print(f\"   â€¢ Hierarchy levels: {len(term_sets)}\")\n        for ts in term_sets[:5]:\n            print(f\"     - {ts}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Donor & Species Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_donor is not None and len(df_donor) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    fig.suptitle('Donor Demographics', fontsize=14, fontweight='bold', y=1.02)\n",
    "    \n",
    "    # Species distribution\n",
    "    ax1 = axes[0]\n",
    "    if 'species_scientific_name' in df_donor.columns:\n",
    "        species_counts = df_donor['species_scientific_name'].value_counts()\n",
    "        colors = sns.color_palette('Set2', len(species_counts))\n",
    "        bars = ax1.bar(range(len(species_counts)), species_counts.values, color=colors)\n",
    "        ax1.set_xticks(range(len(species_counts)))\n",
    "        ax1.set_xticklabels([s.replace(' ', '\\n') for s in species_counts.index], fontsize=9)\n",
    "        ax1.set_ylabel('Number of Donors')\n",
    "        ax1.set_title('A. Species Distribution')\n",
    "        for bar, val in zip(bars, species_counts.values):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                    str(val), ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Sex distribution\n",
    "    ax2 = axes[1]\n",
    "    if 'donor_sex' in df_donor.columns:\n",
    "        sex_counts = df_donor['donor_sex'].value_counts()\n",
    "        colors = ['#FF6B6B' if 'F' in str(s).upper() else '#4ECDC4' for s in sex_counts.index]\n",
    "        wedges, texts, autotexts = ax2.pie(sex_counts.values, labels=sex_counts.index, \n",
    "                                           autopct='%1.1f%%', colors=colors,\n",
    "                                           wedgeprops=dict(edgecolor='white', linewidth=2))\n",
    "        ax2.set_title('B. Sex Distribution')\n",
    "    \n",
    "    # Age distribution\n",
    "    ax3 = axes[2]\n",
    "    if 'donor_age_value' in df_donor.columns:\n",
    "        ages = pd.to_numeric(df_donor['donor_age_value'], errors='coerce').dropna()\n",
    "        if len(ages) > 0:\n",
    "            ax3.hist(ages, bins=15, color='#95E1D3', edgecolor='white', linewidth=1.2)\n",
    "            ax3.axvline(ages.mean(), color='#F38181', linestyle='--', linewidth=2, label=f'Mean: {ages.mean():.1f}')\n",
    "            ax3.set_xlabel('Age')\n",
    "            ax3.set_ylabel('Count')\n",
    "            ax3.set_title('C. Age Distribution')\n",
    "            ax3.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig1_donor_demographics.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Donor data not available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Cluster Distribution & Cell Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if df_cluster is not None and 'number_of_cells' in df_cluster.columns:\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    fig.suptitle('Cluster Analysis', fontsize=14, fontweight='bold', y=1.02)\n    \n    # Cell count distribution (log scale)\n    ax1 = axes[0]\n    cell_counts = df_cluster['number_of_cells'].values\n    ax1.hist(np.log10(cell_counts + 1), bins=30, color='#6C5CE7', edgecolor='white', alpha=0.8)\n    ax1.set_xlabel('logâ‚â‚€(Cell Count + 1)')\n    ax1.set_ylabel('Number of Clusters')\n    ax1.set_title('A. Cell Count Distribution per Cluster')\n    ax1.axvline(np.log10(np.median(cell_counts) + 1), color='#FD79A8', linestyle='--', \n                linewidth=2, label=f'Median: {int(np.median(cell_counts)):,}')\n    ax1.legend()\n    \n    # Top 20 clusters by cell count\n    ax2 = axes[1]\n    top_clusters = df_cluster.nlargest(20, 'number_of_cells')\n    if 'label' in top_clusters.columns:\n        labels = [l[:20] + '...' if len(str(l)) > 20 else str(l) for l in top_clusters['label']]\n    elif 'cluster_alias' in top_clusters.columns:\n        labels = [str(l)[:20] for l in top_clusters['cluster_alias']]\n    else:\n        labels = [f\"Cluster {i}\" for i in range(len(top_clusters))]\n    \n    colors = plt.cm.viridis(np.linspace(0.2, 0.8, 20))\n    ax2.barh(range(len(top_clusters)), top_clusters['number_of_cells'].values, color=colors[:len(top_clusters)])\n    ax2.set_yticks(range(len(top_clusters)))\n    ax2.set_yticklabels(labels, fontsize=8)\n    ax2.set_xlabel('Number of Cells')\n    ax2.set_title('B. Top 20 Clusters by Cell Count')\n    ax2.invert_yaxis()\n    \n    # Cumulative distribution\n    ax3 = axes[2]\n    sorted_counts = np.sort(cell_counts)[::-1]\n    cumsum = np.cumsum(sorted_counts) / sorted_counts.sum() * 100\n    ax3.plot(range(1, len(cumsum) + 1), cumsum, color='#00B894', linewidth=2)\n    ax3.fill_between(range(1, len(cumsum) + 1), cumsum, alpha=0.3, color='#00B894')\n    ax3.axhline(80, color='#FDCB6E', linestyle='--', label='80% threshold')\n    idx_80 = np.where(cumsum >= 80)[0][0] + 1 if any(cumsum >= 80) else len(cumsum)\n    ax3.axvline(idx_80, color='#FDCB6E', linestyle='--')\n    ax3.set_xlabel('Number of Clusters (ranked)')\n    ax3.set_ylabel('Cumulative % of Cells')\n    ax3.set_title(f'C. Cumulative Distribution\\n(Top {idx_80} clusters = 80% cells)')\n    ax3.legend()\n    \n    plt.tight_layout()\n    plt.savefig('fig2_cluster_analysis.png', dpi=150, bbox_inches='tight', facecolor='white')\n    plt.show()\n    \n    # Summary statistics\n    print(f\"\\nCluster Statistics:\")\n    print(f\"  Total clusters: {len(df_cluster):,}\")\n    print(f\"  Total cells: {cell_counts.sum():,}\")\n    print(f\"  Mean cells/cluster: {cell_counts.mean():,.0f}\")\n    print(f\"  Median cells/cluster: {np.median(cell_counts):,.0f}\")\n    print(f\"  Min/Max: {cell_counts.min():,} / {cell_counts.max():,}\")\nelse:\n    print(\"Cluster data not available for visualization.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Cell Quality Control Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_cell_metadata is not None:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    fig.suptitle('Cell Quality Control Metrics', fontsize=14, fontweight='bold', y=1.02)\n",
    "    \n",
    "    # UMI count distribution\n",
    "    ax1 = axes[0]\n",
    "    if 'umi_count' in df_cell_metadata.columns:\n",
    "        umi = df_cell_metadata['umi_count'].dropna()\n",
    "        ax1.hist(np.log10(umi + 1), bins=50, color='#74B9FF', edgecolor='white', alpha=0.8)\n",
    "        ax1.axvline(np.log10(umi.median() + 1), color='#D63031', linestyle='--', \n",
    "                   linewidth=2, label=f'Median: {int(umi.median()):,}')\n",
    "        ax1.set_xlabel('logâ‚â‚€(UMI Count + 1)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('A. UMI Count Distribution')\n",
    "        ax1.legend()\n",
    "    \n",
    "    # Doublet score distribution\n",
    "    ax2 = axes[1]\n",
    "    if 'doublet_score' in df_cell_metadata.columns:\n",
    "        doublet = df_cell_metadata['doublet_score'].dropna()\n",
    "        ax2.hist(doublet, bins=50, color='#A29BFE', edgecolor='white', alpha=0.8)\n",
    "        ax2.axvline(0.5, color='#D63031', linestyle='--', linewidth=2, label='Threshold: 0.5')\n",
    "        pct_doublet = (doublet > 0.5).mean() * 100\n",
    "        ax2.set_xlabel('Doublet Score')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title(f'B. Doublet Score ({pct_doublet:.1f}% > 0.5)')\n",
    "        ax2.legend()\n",
    "    \n",
    "    # Cells per library\n",
    "    ax3 = axes[2]\n",
    "    if 'library_label' in df_cell_metadata.columns:\n",
    "        lib_counts = df_cell_metadata['library_label'].value_counts()\n",
    "        ax3.hist(lib_counts.values, bins=30, color='#55EFC4', edgecolor='white', alpha=0.8)\n",
    "        ax3.axvline(lib_counts.median(), color='#D63031', linestyle='--', \n",
    "                   linewidth=2, label=f'Median: {int(lib_counts.median()):,}')\n",
    "        ax3.set_xlabel('Cells per Library')\n",
    "        ax3.set_ylabel('Number of Libraries')\n",
    "        ax3.set_title(f'C. Cells per Library (n={len(lib_counts)})')\n",
    "        ax3.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig3_qc_metrics.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cell metadata not available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Taxonomy Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if df_taxonomy is not None and 'cluster_annotation_term_set_name' in df_taxonomy.columns:\n    # Count terms per hierarchy level\n    hierarchy_counts = df_taxonomy['cluster_annotation_term_set_name'].value_counts()\n    \n    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n    fig.suptitle('Taxonomy Hierarchy Structure', fontsize=14, fontweight='bold', y=1.02)\n    \n    # Bar chart of terms per level\n    colors = plt.cm.Spectral(np.linspace(0.1, 0.9, len(hierarchy_counts)))\n    bars = ax.barh(range(len(hierarchy_counts)), hierarchy_counts.values, color=colors)\n    ax.set_yticks(range(len(hierarchy_counts)))\n    ax.set_yticklabels([h[:35] + '...' if len(h) > 35 else h for h in hierarchy_counts.index], fontsize=9)\n    ax.set_xlabel('Number of Terms')\n    ax.set_title('Terms per Hierarchy Level')\n    ax.invert_yaxis()\n    for bar, val in zip(bars, hierarchy_counts.values):\n        ax.text(val + 1, bar.get_y() + bar.get_height()/2, str(val), \n                va='center', fontsize=9)\n    \n    plt.tight_layout()\n    plt.savefig('fig4_taxonomy.png', dpi=150, bbox_inches='tight', facecolor='white')\n    plt.show()\n    \n    print(f\"\\nTaxonomy Summary:\")\n    print(f\"  Total annotation terms: {len(df_taxonomy)}\")\n    print(f\"  Hierarchy levels: {len(hierarchy_counts)}\")\nelse:\n    print(\"Taxonomy data not available for visualization.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 UMAP Embedding Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge embeddings with cluster assignments for visualization\n",
    "if df_embeddings is not None and df_cell_cluster is not None:\n",
    "    # Merge data\n",
    "    df_viz = df_embeddings.merge(df_cell_cluster, on='cell_label', how='inner')\n",
    "    \n",
    "    if df_cell_metadata is not None:\n",
    "        merge_cols = ['cell_label']\n",
    "        if 'donor_label' in df_cell_metadata.columns:\n",
    "            merge_cols.append('donor_label')\n",
    "        if 'umi_count' in df_cell_metadata.columns:\n",
    "            merge_cols.append('umi_count')\n",
    "        if 'doublet_score' in df_cell_metadata.columns:\n",
    "            merge_cols.append('doublet_score')\n",
    "        \n",
    "        df_viz = df_viz.merge(df_cell_metadata[merge_cols], on='cell_label', how='left')\n",
    "    \n",
    "    print(f\"Visualization data: {len(df_viz):,} cells with embeddings and annotations\")\n",
    "    print(f\"Columns: {list(df_viz.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if 'df_viz' in dir() and df_viz is not None and len(df_viz) > 0:\n    # Sample for faster plotting\n    n_sample = min(50000, len(df_viz))\n    df_plot = df_viz.sample(n=n_sample, random_state=42)\n    \n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    fig.suptitle('UMAP Embeddings', fontsize=16, fontweight='bold', y=1.01)\n    \n    # A. Colored by cluster (convert string cluster_alias to numeric codes)\n    ax1 = axes[0, 0]\n    if 'cluster_alias' in df_plot.columns:\n        # Get top 20 clusters and assign numeric codes\n        top_clusters = df_plot['cluster_alias'].value_counts().head(20).index.tolist()\n        # Create numeric mapping: top clusters get values 0-19, others get -1\n        cluster_to_code = {c: i for i, c in enumerate(top_clusters)}\n        df_plot['cluster_code'] = df_plot['cluster_alias'].apply(\n            lambda x: cluster_to_code.get(x, -1)\n        )\n        # Plot with numeric codes\n        scatter = ax1.scatter(df_plot['x'], df_plot['y'], \n                             c=df_plot['cluster_code'], cmap='tab20',\n                             s=1, alpha=0.5, rasterized=True, vmin=-1, vmax=19)\n    else:\n        ax1.scatter(df_plot['x'], df_plot['y'], s=1, alpha=0.5, c='gray', rasterized=True)\n    ax1.set_xlabel('UMAP 1')\n    ax1.set_ylabel('UMAP 2')\n    ax1.set_title('A. Colored by Cluster (Top 20)')\n    ax1.set_aspect('equal')\n    \n    # B. Colored by donor\n    ax2 = axes[0, 1]\n    if 'donor_label' in df_plot.columns:\n        donors = df_plot['donor_label'].fillna('Unknown')\n        donor_codes = pd.Categorical(donors).codes\n        scatter = ax2.scatter(df_plot['x'], df_plot['y'], \n                             c=donor_codes, cmap='Spectral',\n                             s=1, alpha=0.5, rasterized=True)\n        plt.colorbar(scatter, ax=ax2, label='Donor')\n    else:\n        ax2.scatter(df_plot['x'], df_plot['y'], s=1, alpha=0.5, c='gray', rasterized=True)\n    ax2.set_xlabel('UMAP 1')\n    ax2.set_ylabel('UMAP 2')\n    ax2.set_title('B. Colored by Donor')\n    ax2.set_aspect('equal')\n    \n    # C. Colored by UMI count\n    ax3 = axes[1, 0]\n    if 'umi_count' in df_plot.columns:\n        umi_log = np.log10(df_plot['umi_count'].fillna(1) + 1)\n        scatter = ax3.scatter(df_plot['x'], df_plot['y'], \n                             c=umi_log, cmap='viridis',\n                             s=1, alpha=0.5, rasterized=True)\n        plt.colorbar(scatter, ax=ax3, label='logâ‚â‚€(UMI + 1)')\n    else:\n        ax3.scatter(df_plot['x'], df_plot['y'], s=1, alpha=0.5, c='gray', rasterized=True)\n    ax3.set_xlabel('UMAP 1')\n    ax3.set_ylabel('UMAP 2')\n    ax3.set_title('C. Colored by UMI Count')\n    ax3.set_aspect('equal')\n    \n    # D. Colored by doublet score\n    ax4 = axes[1, 1]\n    if 'doublet_score' in df_plot.columns:\n        doublet = df_plot['doublet_score'].fillna(0)\n        scatter = ax4.scatter(df_plot['x'], df_plot['y'], \n                             c=doublet, cmap='RdYlBu_r', vmin=0, vmax=1,\n                             s=1, alpha=0.5, rasterized=True)\n        plt.colorbar(scatter, ax=ax4, label='Doublet Score')\n    else:\n        ax4.scatter(df_plot['x'], df_plot['y'], s=1, alpha=0.5, c='gray', rasterized=True)\n    ax4.set_xlabel('UMAP 1')\n    ax4.set_ylabel('UMAP 2')\n    ax4.set_title('D. Colored by Doublet Score')\n    ax4.set_aspect('equal')\n    \n    plt.tight_layout()\n    plt.savefig('fig5_umap_embeddings.png', dpi=150, bbox_inches='tight', facecolor='white')\n    plt.show()\nelse:\n    print(\"Embedding data not available for visualization.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Gene & Library Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "fig.suptitle('Gene & Library Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "# Gene statistics\n",
    "ax1 = axes[0]\n",
    "if df_gene is not None and 'gene_symbol' in df_gene.columns:\n",
    "    symbol_lengths = df_gene['gene_symbol'].str.len()\n",
    "    ax1.hist(symbol_lengths, bins=30, color='#81ECEC', edgecolor='white')\n",
    "    ax1.axvline(symbol_lengths.median(), color='#D63031', linestyle='--', \n",
    "               linewidth=2, label=f'Median: {symbol_lengths.median():.0f}')\n",
    "    ax1.set_xlabel('Gene Symbol Length')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title(f'A. Gene Symbol Length (n={len(df_gene):,})')\n",
    "    ax1.legend()\n",
    "else:\n",
    "    ax1.text(0.5, 0.5, 'Gene data not available', ha='center', va='center')\n",
    "    ax1.set_title('A. Gene Statistics')\n",
    "\n",
    "# Library statistics\n",
    "ax2 = axes[1]\n",
    "if df_library is not None and 'region_of_interest_name' in df_library.columns:\n",
    "    roi_counts = df_library['region_of_interest_name'].value_counts().head(10)\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(roi_counts)))\n",
    "    ax2.barh(range(len(roi_counts)), roi_counts.values, color=colors)\n",
    "    ax2.set_yticks(range(len(roi_counts)))\n",
    "    ax2.set_yticklabels([r[:25] for r in roi_counts.index], fontsize=9)\n",
    "    ax2.set_xlabel('Number of Libraries')\n",
    "    ax2.set_title(f'B. Libraries by Brain Region (n={len(df_library)})')\n",
    "    ax2.invert_yaxis()\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'Library data not available', ha='center', va='center')\n",
    "    ax2.set_title('B. Library Statistics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig6_gene_library.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Integration\n",
    "\n",
    "### 5.1 Prepare Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic ML data with realistic class imbalance and overlap\n",
    "np.random.seed(42)\n",
    "\n",
    "n_cells = 10000\n",
    "n_genes = 100\n",
    "n_classes = 15\n",
    "\n",
    "# Create imbalanced class sizes (power law distribution)\n",
    "class_probs = np.array([1/(i+1)**0.5 for i in range(n_classes)])\n",
    "class_probs /= class_probs.sum()\n",
    "class_sizes = np.random.multinomial(n_cells, class_probs)\n",
    "\n",
    "X_demo = []\n",
    "y_demo = []\n",
    "\n",
    "# Create overlapping clusters with varying separability\n",
    "class_centers = np.random.randn(n_classes, n_genes) * 3\n",
    "\n",
    "for i, size in enumerate(class_sizes):\n",
    "    noise_scale = 0.8 + 0.4 * np.random.rand()\n",
    "    X_class = class_centers[i] + np.random.randn(size, n_genes) * noise_scale\n",
    "    \n",
    "    # Add some mislabeled points (5% noise)\n",
    "    n_noisy = int(size * 0.05)\n",
    "    if n_noisy > 0:\n",
    "        noisy_labels = np.random.choice([j for j in range(n_classes) if j != i], n_noisy)\n",
    "        y_class = np.array([i] * size)\n",
    "        y_class[:n_noisy] = noisy_labels\n",
    "    else:\n",
    "        y_class = np.array([i] * size)\n",
    "    \n",
    "    X_demo.append(X_class)\n",
    "    y_demo.extend(y_class)\n",
    "\n",
    "X_demo = np.vstack(X_demo).astype(np.float32)\n",
    "y_demo = np.array(y_demo)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_demo = scaler.fit_transform(X_demo)\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_demo, y_demo, test_size=0.2, stratify=y_demo, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Classes: {n_classes}\")\n",
    "print(f\"Class distribution (train): {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class CellClassifier(nn.Module):\n",
    "    def __init__(self, n_genes, n_classes, hidden_dims=[256, 128, 64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = n_genes\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(in_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            in_dim = h_dim\n",
    "        layers.append(nn.Linear(in_dim, n_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = CellDataset(X_train, y_train)\n",
    "test_dataset = CellDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CellClassifier(n_genes, n_classes).to(device)\n",
    "print(f\"Model on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PyTorch model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "print(\"Training PyTorch model...\")\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += y_batch.size(0)\n",
    "        train_correct += predicted.eq(y_batch).sum().item()\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, test_correct, test_total = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += y_batch.size(0)\n",
    "            test_correct += predicted.eq(y_batch).sum().item()\n",
    "    \n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    test_acc = 100. * test_correct / test_total\n",
    "    history['train_loss'].append(train_loss / len(train_loader))\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss / len(test_loader))\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/25: Train Acc: {train_acc:.1f}% | Test Acc: {test_acc:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal PyTorch Test Accuracy: {history['test_acc'][-1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TensorFlow model\n",
    "tf_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(n_genes,)),\n",
    "    keras.layers.Dense(256),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(64),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "tf_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Training TensorFlow model...\")\n",
    "tf_history = tf_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=25,\n",
    "    batch_size=128,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=3),\n",
    "        keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_loss, test_acc = tf_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Final TensorFlow Test Accuracy: {test_acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Training Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "fig.suptitle('Training Comparison: PyTorch vs TensorFlow', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history['train_loss'], 'b-', label='PyTorch Train', linewidth=2)\n",
    "ax1.plot(history['test_loss'], 'b--', label='PyTorch Test', linewidth=2)\n",
    "ax1.plot(tf_history.history['loss'], 'r-', label='TensorFlow Train', linewidth=2)\n",
    "ax1.plot(tf_history.history['val_loss'], 'r--', label='TensorFlow Val', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(history['train_acc'], 'b-', label='PyTorch Train', linewidth=2)\n",
    "ax2.plot(history['test_acc'], 'b--', label='PyTorch Test', linewidth=2)\n",
    "ax2.plot([x*100 for x in tf_history.history['accuracy']], 'r-', label='TensorFlow Train', linewidth=2)\n",
    "ax2.plot([x*100 for x in tf_history.history['val_accuracy']], 'r--', label='TensorFlow Val', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig7_training_curves.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Model Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Get predictions from both models\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "    pytorch_logits = model(X_test_tensor).cpu().numpy()\n",
    "    pytorch_preds = pytorch_logits.argmax(axis=1)\n",
    "    pytorch_probs = torch.softmax(torch.FloatTensor(pytorch_logits), dim=1).numpy()\n",
    "\n",
    "tf_probs = tf_model.predict(X_test, verbose=0)\n",
    "tf_preds = tf_probs.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "pytorch_conf = pytorch_probs.max(axis=1)\n",
    "tf_conf = tf_probs.max(axis=1)\n",
    "pytorch_correct = pytorch_preds == y_test\n",
    "tf_correct = tf_preds == y_test\n",
    "\n",
    "print(\"Prediction Summary:\")\n",
    "print(f\"  PyTorch accuracy: {pytorch_correct.mean()*100:.1f}%\")\n",
    "print(f\"  TensorFlow accuracy: {tf_correct.mean()*100:.1f}%\")\n",
    "print(f\"  Agreement: {(pytorch_preds == tf_preds).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "fig.suptitle('Model Behavior Analysis', fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "# A. Confidence Distribution - Correct vs Incorrect (PyTorch)\n",
    "ax1 = fig.add_subplot(2, 3, 1)\n",
    "bins = np.linspace(0, 1, 31)\n",
    "ax1.hist(pytorch_conf[pytorch_correct], bins=bins, alpha=0.7, label='Correct', color='#27AE60', density=True)\n",
    "ax1.hist(pytorch_conf[~pytorch_correct], bins=bins, alpha=0.7, label='Incorrect', color='#E74C3C', density=True)\n",
    "ax1.axvline(pytorch_conf[pytorch_correct].mean(), color='#27AE60', linestyle='--', linewidth=2)\n",
    "ax1.axvline(pytorch_conf[~pytorch_correct].mean(), color='#E74C3C', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Prediction Confidence')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('A. PyTorch Confidence Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# B. Confidence Distribution (TensorFlow)\n",
    "ax2 = fig.add_subplot(2, 3, 2)\n",
    "ax2.hist(tf_conf[tf_correct], bins=bins, alpha=0.7, label='Correct', color='#27AE60', density=True)\n",
    "ax2.hist(tf_conf[~tf_correct], bins=bins, alpha=0.7, label='Incorrect', color='#E74C3C', density=True)\n",
    "ax2.axvline(tf_conf[tf_correct].mean(), color='#27AE60', linestyle='--', linewidth=2)\n",
    "ax2.axvline(tf_conf[~tf_correct].mean(), color='#E74C3C', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Prediction Confidence')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('B. TensorFlow Confidence Distribution')\n",
    "ax2.legend()\n",
    "\n",
    "# C. Per-Class Accuracy Comparison\n",
    "ax3 = fig.add_subplot(2, 3, 3)\n",
    "class_acc_pt = []\n",
    "class_acc_tf = []\n",
    "for c in range(n_classes):\n",
    "    mask = y_test == c\n",
    "    class_acc_pt.append((pytorch_preds[mask] == y_test[mask]).mean() * 100 if mask.sum() > 0 else 0)\n",
    "    class_acc_tf.append((tf_preds[mask] == y_test[mask]).mean() * 100 if mask.sum() > 0 else 0)\n",
    "\n",
    "x = np.arange(n_classes)\n",
    "width = 0.35\n",
    "ax3.bar(x - width/2, class_acc_pt, width, label='PyTorch', color='#3498DB', alpha=0.8)\n",
    "ax3.bar(x + width/2, class_acc_tf, width, label='TensorFlow', color='#E67E22', alpha=0.8)\n",
    "ax3.axhline(np.mean(class_acc_pt), color='#3498DB', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(np.mean(class_acc_tf), color='#E67E22', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Class ID')\n",
    "ax3.set_ylabel('Accuracy (%)')\n",
    "ax3.set_title('C. Per-Class Accuracy')\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 105)\n",
    "\n",
    "# D. Confusion Matrix (PyTorch)\n",
    "ax4 = fig.add_subplot(2, 3, 4)\n",
    "cm = confusion_matrix(y_test, pytorch_preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "im = ax4.imshow(cm_norm, cmap='Blues', vmin=0, vmax=1)\n",
    "ax4.set_xlabel('Predicted')\n",
    "ax4.set_ylabel('True')\n",
    "ax4.set_title('D. Confusion Matrix (PyTorch)')\n",
    "plt.colorbar(im, ax=ax4, label='Proportion')\n",
    "\n",
    "# E. t-SNE of Learned Embeddings\n",
    "ax5 = fig.add_subplot(2, 3, 5)\n",
    "\n",
    "class EmbeddingExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(*list(model.network.children())[:-1])\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "extractor = EmbeddingExtractor(model).to(device)\n",
    "extractor.eval()\n",
    "\n",
    "n_tsne = min(2000, len(X_test))\n",
    "idx = np.random.choice(len(X_test), n_tsne, replace=False)\n",
    "with torch.no_grad():\n",
    "    embeddings = extractor(torch.FloatTensor(X_test[idx]).to(device)).cpu().numpy()\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, max_iter=500)\n",
    "emb_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "scatter = ax5.scatter(emb_2d[:, 0], emb_2d[:, 1], c=y_test[idx], cmap='tab20', s=10, alpha=0.6)\n",
    "ax5.set_xlabel('t-SNE 1')\n",
    "ax5.set_ylabel('t-SNE 2')\n",
    "ax5.set_title('E. Learned Embeddings (t-SNE)')\n",
    "\n",
    "# F. Model Agreement Analysis\n",
    "ax6 = fig.add_subplot(2, 3, 6)\n",
    "both_correct = (pytorch_correct & tf_correct).sum()\n",
    "both_wrong = (~pytorch_correct & ~tf_correct).sum()\n",
    "pt_only = (pytorch_correct & ~tf_correct).sum()\n",
    "tf_only = (~pytorch_correct & tf_correct).sum()\n",
    "\n",
    "categories = ['Both Correct', 'Both Wrong', 'PyTorch Only', 'TF Only']\n",
    "counts = [both_correct, both_wrong, pt_only, tf_only]\n",
    "colors = ['#27AE60', '#E74C3C', '#3498DB', '#E67E22']\n",
    "\n",
    "non_zero = [(c, cat, col) for c, cat, col in zip(counts, categories, colors) if c > 0]\n",
    "if len(non_zero) > 0:\n",
    "    counts_nz = [x[0] for x in non_zero]\n",
    "    labels_nz = [x[1] for x in non_zero]\n",
    "    colors_nz = [x[2] for x in non_zero]\n",
    "    wedges, texts, autotexts = ax6.pie(counts_nz, labels=labels_nz, autopct='%1.1f%%',\n",
    "                                        colors=colors_nz, startangle=90,\n",
    "                                        wedgeprops=dict(edgecolor='white', linewidth=2))\n",
    "ax6.set_title('F. Model Agreement Analysis')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig8_model_behavior.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED MODEL BEHAVIOR STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nConfidence Analysis:\")\n",
    "print(f\"  PyTorch - Correct: mean={pytorch_conf[pytorch_correct].mean():.3f}\")\n",
    "print(f\"  PyTorch - Wrong:   mean={pytorch_conf[~pytorch_correct].mean():.3f}\")\n",
    "print(f\"  TensorFlow - Correct: mean={tf_conf[tf_correct].mean():.3f}\")\n",
    "print(f\"  TensorFlow - Wrong:   mean={tf_conf[~tf_correct].mean():.3f}\")\n",
    "print(f\"\\nModel Agreement:\")\n",
    "print(f\"  Both correct: {both_correct} ({both_correct/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  Both wrong:   {both_wrong} ({both_wrong/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  PyTorch only: {pt_only} ({pt_only/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  TF only:      {tf_only} ({tf_only/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Summary\n\nThis notebook demonstrated comprehensive analysis of the HMBA Basal Ganglia dataset:\n\n### EDA Highlights\n- Multi-species dataset with diverse donors\n- Hierarchical cell type taxonomy with multiple annotation levels\n- Quality-controlled cells with UMAP embeddings\n- Rich metadata across 14 CSV files loaded via Croissant RecordSets\n\n### ML Results\n- PyTorch and TensorFlow models trained successfully\n- Model behavior analysis shows confidence calibration\n- t-SNE visualization reveals learned representations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: {metadata['name']}\")\n",
    "print(f\"Total files: {len(distributions)}\")\n",
    "print(f\"  - H5AD: {len(h5ad_files)}\")\n",
    "print(f\"  - Parquet: {len(parquet_files)}\")\n",
    "print(f\"  - CSV: {len(csv_files)}\")\n",
    "print(f\"\\nFigures generated: 8\")\n",
    "print(f\"\\nFinal Model Accuracies:\")\n",
    "print(f\"  PyTorch: {history['test_acc'][-1]:.1f}%\")\n",
    "print(f\"  TensorFlow: {tf_history.history['val_accuracy'][-1]*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}