{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatiotemporal Water Quality, Contaminant Levels, and Biodiversity Metrics in the Bay of Biscay Exploration with `mlcroissant`\n",
    "This notebook provides a guide for loading and exploring the spatiotemporal water quality dataset using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is provided via a Croissant schema URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `mlcroissant` library is installed\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset URL\n",
    "url = 'https://sen.science/doi/10.71728/senscience.9xzh-z4vm/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata\n",
    "print(f\"{metadata.get('name')}: {metadata.get('description')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the record sets defined in the dataset\n",
    "record_sets_metadata = metadata.get('recordSet', [])\n",
    "\n",
    "for record_set in record_sets_metadata:\n",
    "    print(f\"Record set ID: {record_set.get('@id')}\")\n",
    "    print(f\"Description: {record_set.get('description', 'No description available.')}\")\n",
    "    print(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from a specific record set into a DataFrame for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set\n",
    "record_sets_ids = [record_set.get('@id') for record_set in record_sets_metadata]\n",
    "dataframes = {}\n",
    "\n",
    "# Assuming the first record set for example purposes\n",
    "for record_set_id in record_sets_ids[:1]:\n",
    "    records = list(dataset.records(record_set=record_set_id))\n",
    "    dataframes[record_set_id] = pd.DataFrame(records)\n",
    "\n",
    "chosen_record_set_id = record_sets_ids[0]\n",
    "print(dataframes[chosen_record_set_id].columns.tolist())\n",
    "dataframes[chosen_record_set_id].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data. This section should include operations like removing outliers, transforming data distributions, or grouping data by key attributes to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample EDA: Assuming there is a numeric field available for demonstration\n",
    "if not dataframes[chosen_record_set_id].empty:\n",
    "    numeric_fields = dataframes[chosen_record_set_id].select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "    numeric_field = numeric_fields[0] if numeric_fields else None\n",
    "\n",
    "    if numeric_field:\n",
    "        print(f\"Analyzing numeric field: {numeric_field}\")\n",
    "\n",
    "        # Filter records based on a threshold\n",
    "        threshold = dataframes[chosen_record_set_id][numeric_field].mean()\n",
    "        filtered_df = dataframes[chosen_record_set_id][dataframes[chosen_record_set_id][numeric_field] > threshold]\n",
    "        print(f\"Filtered records with {numeric_field} > {threshold}:\")\n",
    "        print(filtered_df.head())\n",
    "\n",
    "        # Normalize the numeric field\n",
    "        filtered_df[f\"{numeric_field}_normalized\"] = (filtered_df[numeric_field] - filtered_df[numeric_field].mean()) / filtered_df[numeric_field].std()\n",
    "        print(f\"Normalized {numeric_field} for filtered records:\")\n",
    "        print(filtered_df[[numeric_field, f\"{numeric_field}_normalized\"]].head())\n",
    "\n",
    "        # Group by a categorical field if available\n",
    "        categorical_fields = dataframes[chosen_record_set_id].select_dtypes(include=['object']).columns.tolist()\n",
    "        group_field = categorical_fields[0] if categorical_fields else None\n",
    "\n",
    "        if group_field:\n",
    "            grouped_df = filtered_df.groupby(group_field).mean()\n",
    "            print(f\"Grouped data by {group_field}:\")\n",
    "            print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder visualization section\n",
    "# Example: Plot distribution of the numeric field\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if numeric_field:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(dataframes[chosen_record_set_id][numeric_field].dropna(), bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title(f'Distribution of {numeric_field}')\n",
    "    plt.xlabel(numeric_field)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summarize key findings and observations from the dataset exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explored the spatiotemporal dataset on water quality and biodiversity in the Bay of Biscay. Through loading the dataset with `mlcroissant`, we reviewed the available record sets and fields, performed exploratory data analysis by filtering and normalizing data, and visualized the distribution of key variables. This analysis can serve as a foundation for deeper exploration into environmental trends and impacts in coastal ecosystems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}