{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.02 - QA - Physico-Chemical, Biological, and Environmental Measurements Exploration with `mlcroissant`\n",
    "This notebook guides users in loading and exploring the FAIR^2 marine monitoring dataset using the `mlcroissant` library. It follows the Croissant specification for data interoperability and transparency, referencing all entities by their `@id`.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is provided via a Croissant schema URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install mlcroissant for working with Croissant datasets\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Croissant schema URL\n",
    "croissant_url = 'https://sen.science/doi/10.71728/senscience.bg74-tkzq/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(croissant_url)\n",
    "\n",
    "# Print dataset name and description\n",
    "dataset_name = dataset.metadata.name\n",
    "dataset_description = dataset.metadata.description\n",
    "print(f\"{dataset_name}: {dataset_description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs. All entities are referenced by their `@id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available record sets by @id\n",
    "record_sets = dataset.record_sets\n",
    "\n",
    "print(\"Available record sets:\")\n",
    "for rs in record_sets:\n",
    "    print(f\"- RecordSet @id: {rs['@id']}, name: {rs.get('name', 'N/A')}\")\n",
    "\n",
    "# List fields and columns for each record set\n",
    "for rs in record_sets:\n",
    "    print(f\"\\nFields for RecordSet @id: {rs['@id']}:\")\n",
    "    fields = rs.get('fields', [])\n",
    "    for field in fields:\n",
    "        print(f\"  - Field @id: {field['@id']}, name: {field.get('name', 'N/A')}, dataType: {field.get('dataType', 'N/A')}\")\n",
    "    columns = rs.get('columns', [])\n",
    "    if columns:\n",
    "        print(f\"  Columns:\")\n",
    "        for column in columns:\n",
    "            print(f\"    - Column @id: {column['@id']}, name: {column.get('name', 'N/A')}, dataType: {column.get('dataType', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from specific record sets into DataFrames for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set using their @id\n",
    "df_dict = {}\n",
    "\n",
    "# For demonstration, load the first two record sets\n",
    "example_record_set_ids = [rs['@id'] for rs in record_sets[:2]]\n",
    "\n",
    "for rs_id in example_record_set_ids:\n",
    "    print(f\"\\nLoading records for RecordSet @id: {rs_id}\")\n",
    "    records = list(dataset.records(record_set=rs_id))\n",
    "    df = pd.DataFrame(records)\n",
    "    df_dict[rs_id] = df\n",
    "    print(f\"Columns for {rs_id}: {df.columns.tolist()}\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data, referencing all fields by their `@id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a record set and numeric field by @id for demonstration\n",
    "\n",
    "# Select the first loaded record set\n",
    "example_rs_id = example_record_set_ids[0]\n",
    "df = df_dict[example_rs_id]\n",
    "\n",
    "# Identify numeric fields (those with dataType == 'Float' or 'Integer')\n",
    "numeric_fields = []\n",
    "for rs in record_sets:\n",
    "    if rs['@id'] == example_rs_id:\n",
    "        for field in rs.get('fields', []):\n",
    "            if field.get('dataType') in ['Float', 'Integer']:\n",
    "                numeric_fields.append(field['@id'])\n",
    "\n",
    "print(f\"Numeric fields for RecordSet {example_rs_id}: {numeric_fields}\")\n",
    "if len(numeric_fields) == 0:\n",
    "    print(\"No numeric fields found.\")\n",
    "else:\n",
    "    numeric_field_id = numeric_fields[0]       # Use first numeric field\n",
    "    print(f\"Using numeric field @id: {numeric_field_id}\")\n",
    "    # Filter where numeric field > threshold (example threshold: 10)\n",
    "    threshold = 10\n",
    "    if numeric_field_id in df.columns:\n",
    "        filtered_df = df[df[numeric_field_id] > threshold]\n",
    "        print(f\"Filtered records with {numeric_field_id} > {threshold}:\")\n",
    "        print(filtered_df.head())\n",
    "\n",
    "        # Normalize numeric column\n",
    "        filtered_df[f\"{numeric_field_id}_normalized\"] = (\n",
    "            filtered_df[numeric_field_id] - filtered_df[numeric_field_id].mean()\n",
    "        ) / filtered_df[numeric_field_id].std()\n",
    "        print(f\"Normalized {numeric_field_id} for filtered records:\")\n",
    "        print(filtered_df[[numeric_field_id, f\"{numeric_field_id}_normalized\"]].head())\n",
    "\n",
    "        # Choose a grouping field (categorical), for demo use first non-numeric field\n",
    "        group_fields = [field['@id'] for field in rs.get('fields', [])\n",
    "                       if field.get('dataType') not in ['Float', 'Integer']]\n",
    "        if group_fields:\n",
    "            group_field_id = group_fields[0]\n",
    "            if group_field_id in filtered_df.columns:\n",
    "                grouped_df = filtered_df.groupby(group_field_id)[numeric_field_id].mean().reset_index()\n",
    "                print(f\"Grouped mean of {numeric_field_id} by {group_field_id}:\")\n",
    "                print(grouped_df.head())\n",
    "        else:\n",
    "            print(\"No suitable group field found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the distribution of the numeric field for the filtered DataFrame\n",
    "if len(numeric_fields) > 0 and numeric_field_id in filtered_df.columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    filtered_df[numeric_field_id].hist(bins=30)\n",
    "    plt.xlabel(numeric_field_id)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'Distribution of {numeric_field_id} (> {threshold}) in RecordSet {example_rs_id}')\n",
    "    plt.show()\n",
    "\n",
    "    # If grouped_df exists, visualize the group means\n",
    "    if 'grouped_df' in locals():\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(grouped_df[group_field_id], grouped_df[numeric_field_id])\n",
    "        plt.xlabel(group_field_id)\n",
    "        plt.ylabel(f\"Mean {numeric_field_id}\")\n",
    "        plt.title(f\"Mean {numeric_field_id} by {group_field_id}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No numeric field available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "This notebook demonstrates step-by-step loading, exploration, and processing of the FAIR^2 marine monitoring dataset using the mlcroissant library. All data entities were referenced by their `@id`, ensuring reproducibility and transparency. Further analysis can be performed on the loaded DataFrames for scientific and environmental management applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}