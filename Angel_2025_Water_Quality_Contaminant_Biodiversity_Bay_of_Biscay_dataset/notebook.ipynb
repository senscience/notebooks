{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [UPSIDE - QA TEST] - Spatiotemporal Water Quality Exploration with `mlcroissant`\n",
    "This notebook provides a guide for loading and exploring the [UPSIDE - QA TEST] dataset focusing on water quality, contaminant levels, and biodiversity metrics in the Bay of Biscay, using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset source is available via a Croissant schema URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `mlcroissant` library is installed\n",
    "!pip install mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Load metadata and records from the dataset using `mlcroissant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset URL\n",
    "url = 'https://sen.science/doi/10.71728/senscience.9xzh-z4vm/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata\n",
    "print(f\"{metadata.name}: {metadata.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Review available record sets, fields, and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available record sets\n",
    "record_sets = metadata.recordSet\n",
    "for rs in record_sets:\n",
    "    print(f\"Record Set ID: {rs['@id']} - {rs['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "Load data from a specific record set into a DataFrame for analysis. Use the record set and field `@id`s from the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each record set\n",
    "selected_record_set_id = record_sets[0]['@id']  # Assuming we choose the first ID\n",
    "records = list(dataset.records(record_set=selected_record_set_id))\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Apply common data processing steps, such as filtering records based on specific criteria, normalizing numeric fields, and categorizing data. This section should include operations like removing outliers, transforming data distributions, or grouping data by key attributes to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a numeric field for analysis\n",
    "numeric_field = df.columns[1]  # Replace with actual numeric field ID\n",
    "threshold = 10\n",
    "filtered_df = df[df[numeric_field] > threshold]\n",
    "print(f\"Filtered records with {numeric_field} > {threshold}:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Normalize numeric field\n",
    "filtered_df[f\"{numeric_field}_normalized\"] = (filtered_df[numeric_field] - filtered_df[numeric_field].mean()) / filtered_df[numeric_field].std()\n",
    "print(f\"Normalized {numeric_field} for filtered records:\")\n",
    "print(filtered_df[[numeric_field, f\"{numeric_field}_normalized\"]].head())\n",
    "\n",
    "# Group by another field\n",
    "group_field = df.columns[2]  # Replace with actual group field ID\n",
    "if group_field in df.columns:\n",
    "    grouped_df = filtered_df.groupby(group_field).mean()\n",
    "    print(f\"Grouped data by {group_field}:\")\n",
    "    print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Visualize data distributions or relationships between fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distribution of a numeric field\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df[numeric_field], bins=50, alpha=0.7)\n",
    "plt.title(f\"Distribution of {numeric_field}\")\n",
    "plt.xlabel(numeric_field)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summarize key findings and observations from the dataset exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we utilized the `mlcroissant` library to load and explore the [UPSIDE - QA TEST] dataset, focusing on spatiotemporal data related to water quality in the Bay of Biscay. Through data extraction, filtering, normalization, and visualization, we have derived insights into the dataset's structure and content, paving the way for further analysis and application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}