{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydrological and Environmental Measurements in Bay of Biscay and Adjacent Waters Exploration with `mlcroissant`\n",
    "This notebook demonstrates how to load, explore, and analyze the FAIRÂ² dataset (hydrological and environmental measurements in the Bay of Biscay and adjacent waters) using the `mlcroissant` library.\n",
    "\n",
    "### Dataset Source\n",
    "The dataset is described using a Croissant schema and is available at the following URL:\n",
    "\n",
    "```\n",
    "https://sen.science/doi/10.71728/senscience.h3h6-tjan/fair2.json\n",
    "```\n",
    "\n",
    "We will walk step-by-step through the dataset structure, extraction, and analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure mlcroissant is installed in your current Jupyter environment\n",
    "!pip install --quiet mlcroissant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We start by loading metadata from the Croissant schema URL. The `mlcroissant` library provides convenient tooling for accessing both metadata and records defined in the Croissant description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Croissant schema URL\n",
    "croissant_url = 'https://sen.science/doi/10.71728/senscience.h3h6-tjan/fair2.json'\n",
    "\n",
    "# Load the dataset metadata\n",
    "dataset = mlc.Dataset(croissant_url)\n",
    "\n",
    "# Display basic dataset information\n",
    "print(f\"Dataset Name: {dataset.metadata.name}\")\n",
    "print(f\"Description: {dataset.metadata.description}\")\n",
    "print(f\"Published: {dataset.metadata.datePublished}\")\n",
    "print(f\"License: {dataset.metadata.license}\")\n",
    "print(f\"Keywords: {', '.join(dataset.metadata.keywords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "\n",
    "Now, we examine the main record sets available in the dataset, and inspect their fields. *All datastructures are referenced **exclusively by their `@id`** values, consistent with Croissant specifications.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all record sets (tables) defined in the dataset\n",
    "record_sets = list(dataset.metadata.record_sets)\n",
    "\n",
    "if not record_sets:\n",
    "    print('No record sets found in metadata.')\n",
    "else:\n",
    "    print(f\"Found {len(record_sets)} record sets:\\n\")\n",
    "    for rec in record_sets:\n",
    "        print(f\"@id: {rec['@id']}\")\n",
    "        print(f\"  Name: {rec.get('name', '<no name>')}\")\n",
    "        print(f\"  Description: {rec.get('description', '')}\")\n",
    "        # List out fields by @id\n",
    "        fields = rec.get('fields', [])\n",
    "        print(f\"  Fields: {[fld['@id'] for fld in fields]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example record preview:**\n",
    "\n",
    "We choose one record set to preview a few rows by referencing its `@id`. (Update `<record_set_id>` below with the `@id` you want to explore.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a record set of interest by its @id (replace this with a valid one from previous output)\n",
    "example_record_set_id = ''  # e.g. 'sen:water_chemistry_records' (Replace with a valid @id)\n",
    "\n",
    "if example_record_set_id:\n",
    "    print(f'Displaying a few example records for record set: {example_record_set_id}')\n",
    "    for i, record in enumerate(dataset.records(record_set=example_record_set_id)):\n",
    "        print(f'Row {i+1}: {record}')\n",
    "        if i >= 2:\n",
    "            break\n",
    "else:\n",
    "    print('Please update example_record_set_id with a valid @id from the previous cell output.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction\n",
    "\n",
    "Let's extract data from all or selected record sets into pandas DataFrames for further processing. Ensure to use the correct record set `@id`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List record set @id's to extract (add from output of section 2)\n",
    "record_set_ids = []  # Example: ['sen:water_chemistry_records', 'sen:species_abundance_records']\n",
    "\n",
    "dataframes = {}\n",
    "for rec_id in record_set_ids:\n",
    "    print(f\"Loading records for record set: {rec_id} ...\")\n",
    "    records = list(dataset.records(record_set=rec_id))\n",
    "    dataframes[rec_id] = pd.DataFrame(records)\n",
    "\n",
    "# Display column names for the first loaded record set\n",
    "if record_set_ids:\n",
    "    print(f\"\\nColumns for '{record_set_ids[0]}':\\n\", dataframes[record_set_ids[0]].columns.tolist())\n",
    "    dataframes[record_set_ids[0]].head()\n",
    "else:\n",
    "    print('Please specify one or more valid record_set @id values in record_set_ids to extract data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Apply basic analysis steps such as filtering, normalizing, and grouping. This workflow helps prepare and understand the data before modeling or deeper statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose record set and fields (by @id) to analyze (update with your column/field @id)\n",
    "record_set_id = ''  # Example: 'sen:water_chemistry_records'\n",
    "numeric_field_id = ''  # Example: 'sen:nitrate_concentration'\n",
    "group_field_id = ''    # Example: 'sen:site_name'\n",
    "\n",
    "# Perform analysis only if everything specified\n",
    "if record_set_id and numeric_field_id and record_set_id in dataframes:\n",
    "    df = dataframes[record_set_id]\n",
    "    # Filter to numeric (e.g., remove NAs, convert type)\n",
    "    df[numeric_field_id] = pd.to_numeric(df[numeric_field_id], errors='coerce')\n",
    "    threshold = 10\n",
    "    filtered_df = df[df[numeric_field_id] > threshold].copy()\n",
    "    print(f\"Filtered records with '{numeric_field_id}' > {threshold}:\")\n",
    "    print(filtered_df.head())\n",
    "\n",
    "    filtered_df[f\"{numeric_field_id}_normalized\"] = (\n",
    "        (filtered_df[numeric_field_id] - filtered_df[numeric_field_id].mean()) / filtered_df[numeric_field_id].std()\n",
    "    )\n",
    "    print(f\"\\nNormalized '{numeric_field_id}' for filtered records:\")\n",
    "    print(filtered_df[[numeric_field_id, f\"{numeric_field_id}_normalized\"]].head())\n",
    "\n",
    "    # (Optional) Group by\n",
    "    if group_field_id and group_field_id in filtered_df.columns:\n",
    "        grouped_df = filtered_df.groupby(group_field_id)[numeric_field_id].mean().reset_index()\n",
    "        print(f\"\\nGrouped data by '{group_field_id}':\")\n",
    "        print(grouped_df.head())\n",
    "else:\n",
    "    print(\"Please set valid values for record_set_id, numeric_field_id, and ensure data is loaded in dataframes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "Let's visualize numeric distributions or trends using matplotlib or seaborn. (Update variable names to match your field `@id`s.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample plot: histogram for a selected numeric field\n",
    "if record_set_id and numeric_field_id and record_set_id in dataframes:\n",
    "    df = dataframes[record_set_id]\n",
    "    df[numeric_field_id] = pd.to_numeric(df[numeric_field_id], errors='coerce')\n",
    "    plt.figure(figsize=(7,4))\n",
    "    df[numeric_field_id].hist(bins=30)\n",
    "    plt.xlabel(numeric_field_id)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f\"Distribution of {numeric_field_id}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Please load data and set valid record_set_id and numeric_field_id for visualization.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook illustrated:\n",
    "- Loading and understanding Croissant-powered dataset metadata and structure using `mlcroissant`\n",
    "- Accessing and extracting data by `@id`\n",
    "- Performing preliminary EDA with field filtering and normalization\n",
    "- Visualizing numeric distributions for further insight\n",
    "\n",
    "**Tip:** Refer to the Croissant schema to identify `@id`s for record sets, fields, and columns. Using `mlcroissant`, you can efficiently explore large environmental or scientific datasets with complex structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}