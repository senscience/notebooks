{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the National-Scale Environmental Pressure Indicators Dataset\n",
    "\n",
    "## Introduction\n",
    "This notebook provides an exploratory data analysis (EDA) of the \"National-Scale Environmental Pressure Indicators from 1990 to 2050\" dataset. This dataset contains historical (1990–2020) and forecasted (2021–2050) national-level data for key environmental and socioeconomic indicators, including Municipal Solid Waste (MSW) generation, greenhouse gas emissions (CO₂, CH₄, N₂O), GDP per capita (PPP), and population for 43 countries.\n",
    "\n",
    "Learn more:\n",
    "- Data Package doi: [10.71728/senscience.k2f7-p5v9](https://doi.org/10.71728/senscience.k2f7-p5v9)\n",
    "\n",
    "This notebook will guide you through loading, exploring, and visualizing the data to uncover key trends and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install mlcroissant from the source\n",
    "!sudo apt-get install python3-dev graphviz libgraphviz-dev pkg-config\n",
    "!pip install mlcroissant\n",
    "!pip install seaborn tabulate plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "First, we'll load the historical and forecasted data from the provided CSV files into pandas DataFrames. We've also included a commented-out section for loading the data using `mlcroissant` from a `fair2.json` file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- For Future Use: Loading from FAIR² JSON --- #\n",
    "\n",
    "url = 'https://sen.science/doi/10.71728/senscience.k2f7-p5v9/fair2.json'\n",
    "dataset = mlc.Dataset(url)\n",
    "metadata = dataset.metadata.to_json()\n",
    "print(f\"{metadata['name']}: {metadata['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the record sets available in the dataset\n",
    "df_record_sets = pd.DataFrame(metadata[\"recordSet\"])\n",
    "columns_to_keep = {\n",
    "    \"@id\": \"Record Set ID\",\n",
    "    \"description\": \"Description\"\n",
    "}\n",
    "df_record_sets = df_record_sets[list(columns_to_keep.keys())]\n",
    "df_record_sets = df_record_sets.rename(columns=columns_to_keep)\n",
    "\n",
    "# Convert DataFrame to Markdown table\n",
    "markdown_table = tabulate(df_record_sets, headers=\"keys\", tablefmt=\"pipe\", showindex=False)\n",
    "# Render the table as Markdown in Jupyter\n",
    "display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the record sets are named 'historical' and 'forecast'\n",
    "historical_records = dataset.records(record_set='https://sen.science/doi/10.71728/senscience.k2f7-p5v9/recordsets/Historical')\n",
    "forecast_records = dataset.records(record_set='https://sen.science/doi/10.71728/senscience.k2f7-p5v9/recordsets/Forecast')\n",
    "\n",
    "historical_df = pd.DataFrame(historical_records)\n",
    "forecast_df = pd.DataFrame(forecast_records)\n",
    "\n",
    "print(\"Data loaded successfully from FAIR² JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview\n",
    "Let's get a basic understanding of our datasets, including their shapes and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Historical Data Info:\")\n",
    "historical_df.info()\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(\"Forecast Data Info:\")\n",
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "Now, let's dive deeper into the data to find patterns, anomalies, and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in Historical Data:\")\n",
    "print(historical_df.isnull().sum())\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(\"Missing values in Forecast Data:\")\n",
    "print(forecast_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecast data has missing values for emissions. This is expected as these are the values to be predicted. For our EDA, we will focus on the variables that are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Historical Data Summary Statistics\"))\n",
    "display(historical_df.describe())\n",
    "display(Markdown(\"### Forecast Data Summary Statistics\"))\n",
    "display(forecast_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df, record_set=\"Historical\"):\n",
    "    # Base URI from the JSON-LD context\n",
    "    base_uri = \"https://sen.science/doi/10.71728/senscience.k2f7-p5v9/\"\n",
    "    prefix = f\"{base_uri}recordsets/{record_set}/fields/\"\n",
    "    \n",
    "    # Map field IDs (suffixes) to clean names based on the JSON-LD field definitions\n",
    "    field_map = {\n",
    "        \"CountryRegionName\": \"Country Name\",\n",
    "        \"Year\": \"Year\",\n",
    "        \"Population\": \"Population\",\n",
    "        \"GDPcapitaPPPcurrentinternational$\": \"GDP PPP/capita\",\n",
    "        \"MSWgenerationtyear\": \"MSW generation\",\n",
    "        \"CO2emissionstCO2-eqyear\": \"CO₂ emissions\",\n",
    "        \"CH4emissionstCO2-eqyear\": \"CH₄ emissions\",\n",
    "        \"N2OemissionstCO2-eqyear\": \"N₂O emissions\",\n",
    "        \"CH4emissionstCO2-weyear\": \"CH₄ emissions (we)\"\n",
    "    }\n",
    "    \n",
    "    def get_clean_name(col):\n",
    "        if col.startswith(prefix):\n",
    "            # Extract the ID suffix by removing the prefix\n",
    "            suffix = col[len(prefix):]\n",
    "            # Return the mapped name, or the suffix itself if not found in the map\n",
    "            return field_map.get(suffix, suffix)\n",
    "        return col\n",
    "\n",
    "    df.columns = [get_clean_name(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# Apply cleaning\n",
    "historical_df = clean_column_names(historical_df, record_set=\"Historical\")\n",
    "forecast_df = clean_column_names(forecast_df, record_set=\"Forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Distribution of Latest MSW Generation (Choropleth Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd # Ensure pandas is imported as pd\n",
    "import re # Need re for regex\n",
    "\n",
    "# Prepare Historical Data\n",
    "historical_df_subset = historical_df[['Country Name', 'Year', 'MSW generation']].copy()\n",
    "historical_df_subset['Year'] = pd.to_numeric(historical_df_subset['Year'].astype(str)) # Convert byte string to str, then to numeric\n",
    "historical_df_subset['MSW generation'] = pd.to_numeric(historical_df_subset['MSW generation'].astype(str))\n",
    "\n",
    "# Prepare Forecast Data\n",
    "forecast_df_subset = forecast_df[['Country Name', 'Year', 'MSW generation']].copy()\n",
    "\n",
    "# Convert MSW generation to numeric\n",
    "forecast_df_subset['MSW generation'] = pd.to_numeric(forecast_df_subset['MSW generation'].astype(str))\n",
    "\n",
    "# Handle 'Year' column: it can be 'YYYY' or 'SSP_YYYY'\n",
    "# Convert to string first\n",
    "forecast_df_subset['Year'] = forecast_df_subset['Year'].astype(str)\n",
    "\n",
    "# Create a temporary column for extracted years using regex\n",
    "extracted_years = forecast_df_subset['Year'].str.extract(r'_(\\d+)', expand=False)\n",
    "\n",
    "# Fill NaN values in extracted_years with original 'Year' values (for those without 'SSP_')\n",
    "# Then convert to numeric\n",
    "forecast_df_subset['Year'] = pd.to_numeric(extracted_years.fillna(forecast_df_subset['Year']))\n",
    "\n",
    "# Combine datasets\n",
    "combined_df = pd.concat([historical_df_subset, forecast_df_subset], ignore_index=True)\n",
    "\n",
    "# Prepare the latest available data for each country using combined_df\n",
    "latest_year = combined_df.groupby('Country Name')['Year'].max().reset_index()\n",
    "latest_data = pd.merge(combined_df, latest_year, on=['Country Name', 'Year'], how='inner')\n",
    "\n",
    "# Log-transform and cap MSW generation for better visualization\n",
    "# Clip at 1 to avoid log(0) errors. Ensure MSW generation is numeric.\n",
    "latest_data['log10_MSW_capped'] = np.log10(latest_data['MSW generation'].clip(lower=1))\n",
    "\n",
    "vmin = latest_data['log10_MSW_capped'].min()\n",
    "vmax = latest_data['log10_MSW_capped'].max()\n",
    "\n",
    "fig = go.Figure(go.Choropleth(\n",
    "    locations=latest_data[\"Country Name\"].astype(str), # Ensure Country Name is string for plotting\n",
    "    locationmode=\"country names\",\n",
    "    z=latest_data[\"log10_MSW_capped\"],\n",
    "    colorscale=\"Viridis\",\n",
    "    zmin=vmin,\n",
    "    zmax=vmax,\n",
    "    marker_line_color=\"gray\",\n",
    "    marker_line_width=0.7,\n",
    "    # Show actual MSW value in hover tooltip\n",
    "    hovertext=latest_data[\"Country Name\"].astype(str) + \"<br>MSW: \" + latest_data[\"MSW generation\"].apply(lambda x: f\"{x:,.0f}\").astype(str) + \" t/year\",\n",
    "    hoverinfo=\"text\",\n",
    "    showscale=True,\n",
    "    colorbar_title=\"log₁₀(MSW)\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Latest MSW Generation by Country (log₁₀ scale)\",\n",
    "    geo=dict(showframe=False, showcoastlines=True)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below presents a choropleth map visualizing the latest available Municipal Solid Waste (MSW) generation for each country in the dataset, using a logarithmic (log₁₀) scale for improved clarity across a wide range of values. Countries are colored according to their MSW generation, allowing for quick comparison of waste generation levels globally. Hovering over each country reveals its name and the corresponding MSW value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSW Generation Trends for Selected Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data (Re-using the logic to ensure clean execution order)\n",
    "historical_df_subset = historical_df[['Country Name', 'Year', 'MSW generation']].copy()\n",
    "# Ensure 'Year' and 'MSW generation' are numeric after converting from potential byte strings\n",
    "historical_df_subset['Year'] = pd.to_numeric(historical_df_subset['Year'].astype(str))\n",
    "historical_df_subset['MSW generation'] = pd.to_numeric(historical_df_subset['MSW generation'].astype(str))\n",
    "\n",
    "\n",
    "forecast_df_subset = forecast_df[['Country Name', 'Year', 'MSW generation']].copy()\n",
    "\n",
    "# Ensure 'MSW generation' is numeric after converting from potential byte strings\n",
    "forecast_df_subset['MSW generation'] = pd.to_numeric(forecast_df_subset['MSW generation'].astype(str))\n",
    "\n",
    "# Handle 'Year' column in forecast_df_subset: it can be 'YYYY' or 'SSP_YYYY'\n",
    "# Convert to string first\n",
    "forecast_df_subset['Year'] = forecast_df_subset['Year'].astype(str)\n",
    "# Try to extract year from 'SSP_YYYY' format\n",
    "extracted_ssp_years = forecast_df_subset['Year'].str.extract(r'_(\\d+)', expand=False)\n",
    "# Fill NaN values (from non-SSP years) with the original year string, then convert to numeric\n",
    "forecast_df_subset['Year'] = pd.to_numeric(extracted_ssp_years.fillna(forecast_df_subset['Year']))\n",
    "\n",
    "\n",
    "combined_df = pd.concat([historical_df_subset, forecast_df_subset], ignore_index=True)\n",
    "\n",
    "# Ensure 'Country Name' is string type in combined_df before filtering\n",
    "combined_df['Country Name'] = combined_df['Country Name'].astype(str)\n",
    "\n",
    "selected_countries = ['United States', 'China', 'India', 'Brazil']\n",
    "plot_df = combined_df[combined_df['Country Name'].isin(selected_countries)].copy() # Add .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(data=plot_df, x='Year', y='MSW generation', hue='Country Name')\n",
    "plt.title('Historical and Forecasted MSW Generation for Selected Countries')\n",
    "plt.ylabel('MSW Generation (tonnes/year)')\n",
    "plt.xlabel('Year')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the historical and forecasted Municipal Solid Waste (MSW) generation trends for selected countries (United States, China, India, Brazil) from 1990 to 2050. Each line represents a country, illustrating changes in annual MSW generation over time. This visualization highlights both past growth and future projections, allowing for comparison of waste generation trajectories among major economies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix of Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = historical_df[['Population', 'GDP PPP/capita', 'MSW generation', 'CO₂ emissions', 'CH₄ emissions', 'N₂O emissions']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Historical Environmental Indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "This notebook provided a preliminary exploratory data analysis of the National-Scale Environmental Pressure Indicators dataset. We loaded the historical and forecast data, checked for completeness, and generated summary statistics. \n",
    "\n",
    "Our visualizations revealed:\n",
    "- **Global Distribution of Latest MSW Generation**: The choropleth map illustrated the latest available Municipal Solid Waste (MSW) generation for each country, using a log₁₀ scale. This visualization highlighted stark differences in waste generation across countries, with major economies and populous nations producing the most waste.\n",
    "- **MSW Generation Trends**: We observed the historical and projected trends in MSW generation for key countries, highlighting significant increases over time, particularly for developing nations.\n",
    "- **Correlations**: The correlation matrix of the historical data showed strong positive correlations between MSW generation and all three greenhouse gas emissions, as well as between GDP per capita and CO₂ emissions. This suggests a strong link between economic activity, consumption, and environmental impact.\n",
    "This initial analysis sets the stage for more advanced modeling, such as forecasting future emissions based on socioeconomic drivers or analyzing the decoupling of economic growth from environmental pressures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croissant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
