{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Indo-Pacific Atolls Dataset (Comprehensive)\n",
    "\n",
    "## Introduction\n",
    "This notebook provides a comprehensive exploratory data analysis (EDA) of the \"A multi-layer dataset of Indo-Pacific atolls\" dataset. This dataset contains a rich collection of biogeographic, environmental, biodiversity, and human impact data for over 300 atolls across the Indo-Pacific basin, distributed across 21 files.\n",
    "\n",
    "Learn more:\n",
    "- Data Package doi: [10.71728/senscience.4f2j-8h1k](https://sen.science/doi/10.71728/senscience.4f2j-8h1k/)\n",
    "\n",
    "As a FAIR¬≤ Data Package, it ensures accessibility, interoperability, and AI-readiness, supporting research and policy aligned with European directives. FAIR¬≤ datasets follow the MLCommons **Croissant** ü•ê format for machine learning datasets. See the [MLCommons Croissant Format Specification](https://docs.mlcommons.org/croissant/docs/croissant-spec.html).\n",
    "\n",
    "This notebook will guide you through loading all the datasets, integrating them into a master DataFrame, and visualizing the combined data to uncover key trends and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install mlcroissant from the source\n",
    "!sudo apt-get install python3-dev graphviz libgraphviz-dev pkg-config\n",
    "!pip install mlcroissant\n",
    "!pip install seaborn tabulate plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from functools import reduce\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "First, we'll use the `mlcroissant` library to load all 21 record sets defined in the `fair2.json` metadata file. The library reads the metadata and loads the corresponding data into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'jsonPath', 'isLiveDataset', 'fileProperty', 'subField', 'data', 'includes', 'path', 'md5', 'replace', 'regex', 'format', 'key', 'transform', 'parentField', 'repeated', 'fileSet', 'examples', 'references', 'separator', 'sc'}\n",
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(Steibl_2025_indo_pacific_atoll_dataset)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading record set: atoll_biogeography.csv\n",
      "Loading record set: atoll_diversity_arthropods.csv\n",
      "Loading record set: atoll_diversity_arthropods_refs.csv\n",
      "Loading record set: atoll_diversity_birds.csv\n",
      "Loading record set: atoll_diversity_birds_refs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://sen.science/doi/10.71728/senscience.4f2j-8h1k/resources/record-sets/atoll_diversity_birds_refs.csv...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 455k/455k [00:00<00:00, 9.68MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading record set: atoll_diversity_landcrabs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://sen.science/doi/10.71728/senscience.4f2j-8h1k/resources/record-sets/atoll_diversity_landcrabs.csv...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.5k/14.5k [00:00<00:00, 20.8MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading record set: atoll_diversity_landcrabs_refs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://sen.science/doi/10.71728/senscience.4f2j-8h1k/resources/record-sets/atoll_diversity_landcrabs_refs.csv...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103k/103k [00:00<00:00, 1.60MiB/s]\n"
     ]
    },
    {
     "ename": "GenerationError",
     "evalue": "An error occured during the streaming generation of the dataset, more specifically during the operation Download(https://sen.science/doi/10.71728/senscience.4f2j-8h1k/resources/atoll_diversity_landcrabs_refs)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/code/croissant-1/python/mlcroissant/mlcroissant/_src/operation_graph/execute.py:119\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m    118\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, operation)\n\u001b[0;32m--> 119\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/code/croissant-1/python/mlcroissant/mlcroissant/_src/operation_graph/operations/download.py:233\u001b[0m, in \u001b[0;36mDownload.call\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_from_http(filepath)\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is downloaded to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mcontent_url, os\u001b[38;5;241m.\u001b[39mfspath(filepath)\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/code/croissant-1/python/mlcroissant/mlcroissant/_src/operation_graph/operations/download.py:179\u001b[0m, in \u001b[0;36mDownload._check_hash\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mis_v0():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHash of downloaded file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not identical with the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reference in the Croissant JSON-LD. Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhex_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (hex) / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase64_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (base64)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Hash of downloaded file /Users/cristina.gonzalez/.cache/croissant/download/croissant-ca07183f525cbb0f9e49ef960940ec664e33d50e0023db45b17cfa2b5dfe0b61 is not identical with the reference in the Croissant JSON-LD. Expected: 807f8eb0e59d64a4f4cd02a2da9f9e8e4afadbbc6d692fb1cd25d3f40ce1bff1 - Got: 8a7033ccee0b0202a64dcba83ee4d8878d1da7886b63baa0ecd9e4086a97101f (hex) / inAzzO4LAgKmTcuoPuTYh40dp4hrY7qg7NnkCGqXEB8= (base64)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGenerationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading record set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrs\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m records \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mrecords(rs\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# FIX: mlcroissant creates columns with names like 'record_set/column'. We strip the prefix.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [col\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[0;32m~/Documents/code/croissant-1/python/mlcroissant/mlcroissant/_src/datasets.py:166\u001b[0m, in \u001b[0;36mRecords.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# We can stream the dataset iff the operation graph is a path graph (meaning\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# that all operations lie on a single straight line, i.e. have an\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# in-degree of 0 or 1. That means that the operation graph is a single line\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# (without external joins for example).\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_streamable_dataset(operations):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[1;32m    167\u001b[0m         record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_set,\n\u001b[1;32m    168\u001b[0m         operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_sequentially(\n\u001b[1;32m    172\u001b[0m         record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_set, operations\u001b[38;5;241m=\u001b[39moperations\n\u001b[1;32m    173\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/code/croissant-1/python/mlcroissant/mlcroissant/_src/operation_graph/execute.py:121\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m    119\u001b[0m         result \u001b[38;5;241m=\u001b[39m operation\u001b[38;5;241m.\u001b[39mcall(result)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GenerationError(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occured during the streaming generation of the dataset, more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m specifically during the operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mGenerationError\u001b[0m: An error occured during the streaming generation of the dataset, more specifically during the operation Download(https://sen.science/doi/10.71728/senscience.4f2j-8h1k/resources/atoll_diversity_landcrabs_refs)"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the Croissant metadata file\n",
    "#ds = mlc.Dataset('https://sen.science/doi/10.71728/senscience.4f2j-8h1k/fair2.json')\n",
    "ds = mlc.Dataset('./fair2.json')\n",
    "\n",
    "# Load all record sets into a dictionary of pandas DataFrames\n",
    "# The key is the record set name, and the value is the DataFrame\n",
    "dataframes = {}\n",
    "for rs in ds.metadata.record_sets:\n",
    "    print(f\"Loading record set: {rs.name}\")\n",
    "    records = ds.records(rs.id)\n",
    "    df = pd.DataFrame(list(records))\n",
    "    # FIX: mlcroissant creates columns with names like 'record_set/column'. We strip the prefix.\n",
    "    df.columns = [col.split('/')[-1] for col in df.columns]\n",
    "    dataframes[rs.name] = df\n",
    "\n",
    "# Assign dataframes to the variables used in the original notebook.\n",
    "main_df = dataframes['atoll_main.csv']\n",
    "biogeography_df = dataframes['atoll_biogeography_310_tidy.csv']\n",
    "environmental_df = dataframes['atoll_environmental.csv']\n",
    "oceanographic_df = dataframes['atoll_oceanographic.csv']\n",
    "landclass_df = dataframes['atoll_landclassification.csv']\n",
    "populations_df = dataframes['atoll_populations.csv']\n",
    "military_df = dataframes['atoll_military_use.csv']\n",
    "reefscape_df = dataframes['atoll_reefscape.csv']\n",
    "seabird_species_df = dataframes['atoll_seabird_population_by_species.csv']\n",
    "seabird_totals_df = dataframes['atoll_seabird_population_totals.csv']\n",
    "plants_df = dataframes['atoll_diversity_plants.csv']\n",
    "birds_df = dataframes['atoll_diversity_birds.csv']\n",
    "reptiles_df = dataframes['atoll_diversity_reptiles.csv']\n",
    "arthropods_df = dataframes['atoll_diversity_arthropods.csv']\n",
    "landcrabs_df = dataframes['atoll_diversity_landcrabs.csv']\n",
    "mammals_df = dataframes['atoll_diversity_native-mammals.csv']\n",
    "\n",
    "# Load reference files (not used in the main merge but loaded for completeness)\n",
    "plants_refs_df = dataframes['atoll_diversity_plants_refs.csv']\n",
    "reptiles_refs_df = dataframes['atoll_diversity_reptiles_refs.csv']\n",
    "arthropods_refs_df = dataframes['atoll_diversity_arthropods_refs.csv']\n",
    "landcrabs_refs_df = dataframes['atoll_diversity_landcrabs_refs.csv']\n",
    "mammals_refs_df = dataframes['atoll_diversity_native-mammals_refs.csv']\n",
    "\n",
    "print(\"\\nAll record sets loaded successfully using mlcroissant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset Metadata\n",
    "Let's inspect the dataset's top-level metadata to understand its name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset's metadata as a JSON-like dictionary\n",
    "metadata = ds.metadata.to_json()\n",
    "\n",
    "# Print the name and description\n",
    "name = metadata.get('name', 'N/A')\n",
    "# The description is under 'description' for Croissant < 1.0, and a list in > 1.0\n",
    "description_obj = metadata.get('description', 'N/A')\n",
    "if isinstance(description_obj, list):\n",
    "    description = description_obj[0].get('@value', 'N/A')\n",
    "else:\n",
    "    description = description_obj\n",
    "    \n",
    "print(f\"{name}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Integration\n",
    "To perform a holistic analysis, we will process and merge these datasets into a single, comprehensive DataFrame using the 'atoll' column as the common key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Pre-process and summarize data --- #\n",
    "\n",
    "# In some CSVs, there are invalid rows that are repetitions of the header.\n",
    "# We will clean these by filtering out rows where the 'atoll' column has the value 'atoll'.\n",
    "# We apply this to all biodiversity dataframes to be safe.\n",
    "plants_df = plants_df[plants_df['atoll'] != 'atoll'].copy()\n",
    "birds_df = birds_df[birds_df['atoll'] != 'atoll'].copy()\n",
    "reptiles_df = reptiles_df[reptiles_df['atoll'] != 'atoll'].copy()\n",
    "arthropods_df = arthropods_df[arthropods_df['atoll'] != 'atoll'].copy()\n",
    "landcrabs_df = landcrabs_df[landcrabs_df['atoll'] != 'atoll'].copy()\n",
    "mammals_df = mammals_df[mammals_df['atoll'] != 'atoll'].copy()\n",
    "\n",
    "# This cleaning may cause some columns to be loaded as 'object' type. Let's fix presence columns.\n",
    "for df in [birds_df, reptiles_df, arthropods_df, landcrabs_df, mammals_df]:\n",
    "    if 'presence' in df.columns:\n",
    "        df['presence'] = pd.to_numeric(df['presence'], errors='coerce')\n",
    "\n",
    "# Pivot the reefscape data from long to wide format\n",
    "reefscape_wide_df = reefscape_df.pivot(index='atoll', columns='metric', values='value').reset_index()\n",
    "\n",
    "# Calculate species richness for each biodiversity group\n",
    "plant_richness = plants_df.groupby('atoll')['species'].nunique().reset_index().rename(columns={'species': 'plant_richness'})\n",
    "bird_richness = birds_df.groupby('atoll')['family_species'].nunique().reset_index().rename(columns={'family_species': 'bird_richness'})\n",
    "reptile_richness = reptiles_df.groupby('atoll')['species'].nunique().reset_index().rename(columns={'species': 'reptile_richness'})\n",
    "arthropod_richness = arthropods_df.groupby('atoll')['species'].nunique().reset_index().rename(columns={'species': 'arthropod_richness'})\n",
    "landcrab_richness = landcrabs_df.groupby('atoll')['species'].nunique().reset_index().rename(columns={'species': 'landcrab_richness'})\n",
    "mammal_richness = mammals_df.groupby('atoll')['species'].nunique().reset_index().rename(columns={'species': 'mammal_richness'})\n",
    "\n",
    "# --- 2. Merge all dataframes --- #\n",
    "\n",
    "# Some dataframes have a 'country' column, which would be duplicated from the main_df.\n",
    "# We drop it from the other dataframes before merging.\n",
    "if 'country' in populations_df.columns:\n",
    "    populations_df = populations_df.drop(columns=['country'])\n",
    "if 'country' in military_df.columns:\n",
    "    military_df = military_df.drop(columns=['country'])\n",
    "    \n",
    "data_frames = [\n",
    "    main_df.drop_duplicates(subset='atoll'),\n",
    "    biogeography_df,\n",
    "    environmental_df,\n",
    "    oceanographic_df,\n",
    "    landclass_df,\n",
    "    populations_df,\n",
    "    military_df,\n",
    "    seabird_totals_df,\n",
    "    reefscape_wide_df,\n",
    "    plant_richness, bird_richness, reptile_richness, arthropod_richness, landcrab_richness, mammal_richness\n",
    "]\n",
    "\n",
    "# Use reduce to iteratively merge all dataframes on 'atoll'\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on='atoll', how='left'), data_frames)\n",
    "\n",
    "display(Markdown(\"### Fully Integrated Atoll Data\"))\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "Now, let's explore the fully integrated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Overview of the Integrated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Integrated Data Info:\")\n",
    "print(f\"Shape of the merged dataframe: {merged_df.shape}\")\n",
    "merged_df.info(verbose=False, max_cols=0) # Get a concise summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Distribution of Atolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Mapbox token provided by the user\n",
    "mapbox_token = \"pk.eyJ1IjoiY3Jpc2JldGg0NiIsImEiOiJjbWM0dG1jeGMwa3Y0MmpzYTRobjM3NHp3In0.kGGMStYgqzcNE-i5u9wUMw\"\n",
    "px.set_mapbox_access_token(mapbox_token)\n",
    "\n",
    "# FIX: The TypeError occurs because some string columns are loaded as bytes.\n",
    "# We need to decode them to strings before plotting.\n",
    "for col in ['atoll', 'region', 'country']:\n",
    "    if col in merged_df.columns:\n",
    "        # Apply a function to decode bytes to string, and leave other types as they are.\n",
    "        merged_df[col] = merged_df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "# Ensure numeric columns are properly typed for the plot, coercing errors\n",
    "for col in ['lat', 'long', 'human_population', 'total_atoll_area_sqkm']:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "\n",
    "# Drop rows where lat/lon are missing, as they can't be plotted.\n",
    "merged_df.dropna(subset=['lat', 'long'], inplace=True)\n",
    "        \n",
    "# Create the interactive map\n",
    "fig = px.scatter_mapbox(\n",
    "    merged_df,\n",
    "    lat=\"lat\",\n",
    "    lon=\"long\",\n",
    "    hover_name=\"atoll\",\n",
    "    hover_data=[\"region\", \"country\", \"human_population\"],\n",
    "    color=\"region\",\n",
    "    size=\"total_atoll_area_sqkm\",\n",
    "    color_continuous_scale=px.colors.cyclical.IceFire,\n",
    "    size_max=15,\n",
    "    zoom=1,\n",
    "    height=600,\n",
    "    title=\"Global Distribution of Indo-Pacific Atolls\"\n",
    ")\n",
    "\n",
    "fig.update_layout(mapbox_style=\"satellite-streets\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species-Area Relationship Across Different Taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Species-Area Relationships Across Taxa', fontsize=16)\n",
    "\n",
    "sns.regplot(ax=axes[0, 0], data=merged_df, x='land_area_sqkm', y='plant_richness').set(xscale='log', title='Plants')\n",
    "sns.regplot(ax=axes[0, 1], data=merged_df, x='land_area_sqkm', y='bird_richness').set(xscale='log', title='Birds')\n",
    "sns.regplot(ax=axes[1, 0], data=merged_df, x='land_area_sqkm', y='reptile_richness').set(xscale='log', title='Reptiles')\n",
    "sns.regplot(ax=axes[1, 1], data=merged_df, x='land_area_sqkm', y='arthropod_richness').set(xscale='log', title='Arthropods')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('Land Area (sq km)')\n",
    "    ax.set_ylabel('Species Richness')\n",
    "    ax.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix of Integrated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "corr_cols = ['land_area_sqkm', 'annual_precipitation_mm', 'temp', 'human_population', 'median_nbirds', 'plant_richness', 'bird_richness', 'reptile_richness', 'distance_continent_km']\n",
    "\n",
    "# Ensure columns for correlation are numeric, coercing errors to NaN\n",
    "for col in corr_cols:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "        \n",
    "corr_matrix = merged_df[corr_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Key Atoll Indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "This notebook provided a comprehensive exploratory data analysis by integrating all 21 files of the Indo-Pacific Atolls dataset.\n",
    "\n",
    "Our visualizations revealed:\n",
    "- **Geographic Distribution**: We mapped the global distribution of the atolls, observing their concentration in distinct regions of the Indo-Pacific.\n",
    "- **Species-Area Relationship**: A classic ecological pattern was consistently observed across multiple taxa, where atolls with larger land areas tend to support a higher number of species.\n",
    "- **Correlations**: The correlation matrix highlighted several important relationships. Land area is positively correlated with species richness across all taxa and with seabird populations. Human population shows a negative correlation with seabird populations, suggesting potential impacts of human presence on wildlife. Distance from the continent also shows a negative correlation with plant and reptile richness, indicating the role of isolation in biodiversity.\n",
    "\n",
    "This integrated analysis unlocks a deeper understanding of the complex interplay between physical, biological, and human factors across these unique atoll ecosystems, paving the way for more advanced modeling and conservation research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croissant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
